{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOcC2UuZuWnIz3USD8MrIc5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaiTechTinker/LLMpract/blob/master/LLM_tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htakUgBSr74e",
        "outputId": "35d78d49-baf4-4917-80a6-6e0b54fa51b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# filepath=drive.mount('/content/drive/My Drive/LLM_pract/the-verdict.txt')\n",
        "drive.mount('/content/drive')\n",
        "# real_Path=drive.mount(filepath)\n",
        "# with open(real_Path,'r',encoding='utf-8') as f:\n",
        "#  text=f.read()\n",
        "# print(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath='/content/drive/My Drive/LLM_pract/the-verdict.txt'\n",
        "with open(filepath,'r',encoding='utf-8') as f:\n",
        "  text=f.read()\n",
        "print(len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-CwMHLktCXb",
        "outputId": "14304ba0-5825-4fb1-dbbc-a02c47bfba3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3cBZWhOzc0q",
        "outputId": "77919a88-be3c-41da-ab6b-9156ca97cf33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import re\n",
        "# re_text=\"hello, world. This i a text\"\n",
        "# result=re.split(r'([,.]\\s)',re_text)\n",
        "# new_result=[item.strip() for item in result]\n",
        "# print(result)\n",
        "# print(new_result)"
      ],
      "metadata": {
        "id": "_n7lg8VFzi-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result=re.split(r'([,.?-_!:\"\\']\\s)',text)\n",
        "# new_result=[item.strip() for item in result]\n",
        "# print(new_result[:120])"
      ],
      "metadata": {
        "id": "tFozCOAp1yey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "preprocessed = [item.strip() for item in result if item.strip()]\n",
        "print(preprocessed[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjTckoUD5SVI",
        "outputId": "6c42dd0e-070b-4484-b391-9290a057ca60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(', 'Though', 'I', 'rather', 'thought', 'it', 'would', 'have', 'been', 'Rome', 'or', 'Florence', '.', ')', '\"', 'The', 'height', 'of', 'his', 'glory', '\"', '--', 'that', 'was', 'what', 'the', 'women', 'called', 'it', '.', 'I', 'can', 'hear', 'Mrs', '.', 'Gideon', 'Thwing', '--', 'his', 'last', 'Chicago', 'sitter', '--']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(preprocessed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDPMC7mK5to2",
        "outputId": "d265d725-d4c2-4bc0-fb0c-dc23701d73ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "allwords=sorted(set(preprocessed))\n",
        "print(len(allwords))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFpsQqQw777z",
        "outputId": "f4e0aec9-d0a4-4ae3-8363-956fb68e9e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab={word:index for index,word in enumerate(allwords)}\n",
        "for i,word in enumerate(vocab.items()):\n",
        "  print(word)\n",
        "  if i ==50:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtmREMn28QEi",
        "outputId": "02263edf-d78b-4b3e-d3d2-363abbd4785f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n",
            "('A', 11)\n",
            "('Ah', 12)\n",
            "('Among', 13)\n",
            "('And', 14)\n",
            "('Are', 15)\n",
            "('Arrt', 16)\n",
            "('As', 17)\n",
            "('At', 18)\n",
            "('Be', 19)\n",
            "('Begin', 20)\n",
            "('Burlington', 21)\n",
            "('But', 22)\n",
            "('By', 23)\n",
            "('Carlo', 24)\n",
            "('Chicago', 25)\n",
            "('Claude', 26)\n",
            "('Come', 27)\n",
            "('Croft', 28)\n",
            "('Destroyed', 29)\n",
            "('Devonshire', 30)\n",
            "('Don', 31)\n",
            "('Dubarry', 32)\n",
            "('Emperors', 33)\n",
            "('Florence', 34)\n",
            "('For', 35)\n",
            "('Gallery', 36)\n",
            "('Gideon', 37)\n",
            "('Gisburn', 38)\n",
            "('Gisburns', 39)\n",
            "('Grafton', 40)\n",
            "('Greek', 41)\n",
            "('Grindle', 42)\n",
            "('Grindles', 43)\n",
            "('HAD', 44)\n",
            "('Had', 45)\n",
            "('Hang', 46)\n",
            "('Has', 47)\n",
            "('He', 48)\n",
            "('Her', 49)\n",
            "('Hermia', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "  def __init__(self,vocab):\n",
        "    self.str_to_int=vocab\n",
        "    self.int_to_str={i:s for s,i in vocab.items()}\n",
        "  def encode(self, text):\n",
        "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "\n",
        "        preprocessed = [\n",
        "            item.strip() for item in preprocessed if item.strip()\n",
        "        ]\n",
        "        ids=[]\n",
        "        for s in preprocessed:\n",
        "          if s not in self.str_to_int:\n",
        "            continue\n",
        "          ids.append(self.str_to_int[s])\n",
        "        return ids\n",
        "\n",
        "  def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        # Replace spaces before the specified punctuations\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "kP7mQLUl-OXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "\n",
        "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
      ],
      "metadata": {
        "id": "mr0G9Ks8MnYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YYDQUPyMq3C",
        "outputId": "380e5cfd-d666-463e-dd18-84c5b747e3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1132"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN-4H4N3Mv-N",
        "outputId": "278403b5-b144-47db-9838-c77a9105fafe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1127)\n",
            "('your', 1128)\n",
            "('yourself', 1129)\n",
            "('<|endoftext|>', 1130)\n",
            "('<|unk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class tokenizerV2:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "        preprocessed = [\n",
        "            item if item in self.str_to_int\n",
        "            else \"<|unk|>\" for item in preprocessed # the <unk> will be unknown with the largest integer\n",
        "        ]\n",
        "\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        # Replace spaces before the specified punctuations\n",
        "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
        "        # return text(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "Ex3rF6MtEEw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(vocab)\n",
        "\n",
        "text = \"\"\"\"It's the last he painted, you know,\"\n",
        "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnzdTleNCk0G",
        "outputId": "684d8e15-fcec-45c0-d3fe-9f98bdd45056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tokenizerV2(vocab)\n",
        "\n",
        "text1 = \"Hello, do you like tea?\"\n",
        "text2 = \"In the sunlit terraces of the palace.\"\n",
        "\n",
        "text = \" <|endoftext|> \".join((text1, text2))\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bD-ZWh8M6aO",
        "outputId": "1cce3acb-2bd7-414a-fa2f-134680fd0c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0F0em3pM9Ng",
        "outputId": "4d94cc99-996f-4068-dd74-180d772b030d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = tokenizer.encode(text)\n",
        "tokenizer.decode(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dZkonv25NwNZ",
        "outputId": "7a5db150-0128-41e8-f2d0-c58aeb2ad974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer=tiktoken.get_encoding(\"gpt2\")\n"
      ],
      "metadata": {
        "id": "rHKDULVnOHrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=(\"hello, do you like tea?<|endoftext|> In the sunlit terrace\"\"of someunlnowpalce\")\n",
        "ids=tokenizer.encode(text,allowed_special={\"<|endoftext|>\"})\n",
        "strings=tokenizer.decode(ids)\n",
        "print(ids)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF_MtMlDjL1W",
        "outputId": "055e0ef3-162f-4b15-eb9d-f7337014ee78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[31373, 11, 466, 345, 588, 8887, 30, 50256, 554, 262, 4252, 18250, 8812, 558, 1659, 617, 403, 75, 2197, 18596, 344]\n",
            "hello, do you like tea?<|endoftext|> In the sunlit terraceof someunlnowpalce\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "enc = tiktoken.get_encoding(\"o200k_base\")\n",
        "ids=enc.encode(text,allowed_special={\"<|endoftext|>\"})\n",
        "print(ids)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y4DjWvRlZkV",
        "outputId": "14a0f31d-8473-4687-95d3-86e1ad73b531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[24912, 11, 621, 481, 1299, 17966, 30, 199999, 730, 290, 7334, 32758, 51551, 1440, 1236, 373, 2943, 384, 18413, 400]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating input target pairs\n"
      ],
      "metadata": {
        "id": "IJYy4OV2sMCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(filepath,'r',encoding=\"utf-8\") as f:\n",
        "  text=f.read()\n",
        "enc_text=enc.encode(text,allowed_special={\"<|endoftext|>\"})\n",
        "print(len(enc_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_aRRCJTsRHt",
        "outputId": "56dcf767-03cc-4d3b-db9f-9e2dd825d86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample=enc_text[50:]\n",
        "print(enc_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSZV2Fextjwu",
        "outputId": "b6296142-de07-44a7-ecc2-95a6fe6505da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11166, 306, 261, 38350, 402, 290, 123397, 13, 350, 52861, 357, 7542, 4525, 480, 1481, 679, 1339, 27388, 503, 62520, 16803, 30289, 4679, 328, 1232, 40373, 150535, 14116, 673, 1412, 290, 5142, 4358, 480, 13, 357, 665, 9598, 31127, 13, 183881, 263, 748, 3964, 375, 38520, 2174, 16864, 86581, 375, 613, 528, 7443, 1232, 537, 8218, 562, 65927, 4598, 13, 392, 2566, 4165, 4275, 2966, 316, 4952, 290, 1432, 328, 922, 8723, 461, 3499, 869, 26, 889, 357, 4128, 2411, 328, 484, 11, 9655, 13, 41767, 6595, 375, 3086, 6266, 316, 16880, 83, 382, 722, 357, 2411, 328, 3692, 623, 2195, 11, 402, 31127, 13, 748, 3964, 885, 36968, 11, 118583, 1617, 1175, 6435, 62, 472, 5495, 1023, 1504, 45264, 306, 448, 34768, 22932, 328, 62971, 13, 1958, 480, 673, 625, 1606, 290, 31127, 13, 748, 86, 963, 1218, 116720, 295, 13, 32183, 625, 290, 67557, 39779, 535, 25186, 826, 11, 540, 290, 2174, 499, 4055, 263, 28360, 2356, 11, 18145, 668, 2254, 165003, 33750, 885, 392, 97198, 2469, 39961, 1, 316, 2891, 11, 483, 37095, 306, 1335, 9623, 25, 392, 2167, 8712, 625, 1631, 7557, 1617, 1299, 2418, 159896, 16936, 5038, 28689, 1819, 290, 172396, 328, 39779, 535, 885, 37095, 357, 9879, 3741, 316, 4950, 290, 2840, 483, 2801, 13823, 536, 13, 69180, 10874, 165003, 33750, 0, 623, 5142, 1458, 2452, 2395, 375, 278, 673, 38938, 484, 1023, 1757, 116720, 2395, 13, 32417, 1232, 2316, 3316, 30732, 125040, 1504, 10542, 11, 326, 306, 1232, 2316, 10552, 35509, 261, 11426, 88762, 13, 21768, 144893, 30, 30391, 13, 1843, 480, 1504, 11, 290, 61170, 328, 290, 13709, 673, 16266, 9321, 656, 3389, 97481, 22646, 4356, 11, 1218, 11, 306, 722, 1899, 13963, 11, 11311, 842, 306, 290, 124906, 261, 1869, 65655, 392, 630, 97861, 1, 402, 10874, 375, 690, 328, 2617, 2356, 88, 10604, 92179, 483, 7526, 11814, 1629, 484, 357, 679, 10542, 350, 40, 14219, 2891, 656, 15904, 8, 11223, 316, 165003, 33750, 885, 21352, 13, 1958, 813, 375, 38520, 14062, 2447, 28603, 164291, 133470, 375, 3086, 14266, 41018, 14769, 842, 11, 326, 11, 472, 31127, 13, 748, 3964, 1458, 35996, 11, 290, 3911, 328, 392, 38, 276, 33750, 82, 1, 5981, 869, 364, 3206, 673, 625, 7892, 3407, 2101, 4849, 484, 11, 306, 290, 4165, 328, 261, 3120, 7449, 6, 1211, 3321, 402, 290, 123397, 11, 480, 24645, 20236, 316, 668, 316, 6213, 4436, 165003, 33750, 1458, 4335, 869, 1232, 21352, 13, 2160, 39755, 11, 480, 2715, 673, 261, 96085, 4792, 13, 2514, 142717, 1232, 11527, 1481, 679, 1339, 3101, 4224, 375, 38520, 9510, 2353, 2540, 1458, 1339, 33793, 290, 195009, 328, 10326, 484, 31127, 13, 165003, 33750, 1458, 392, 40125, 5083, 2395, 1917, 3692, 2214, 31127, 13, 165003, 33750, 375, 288, 2238, 375, 26355, 625, 49030, 7892, 11685, 261, 1284, 1934, 10874, 885, 14062, 1458, 1339, 6697, 13, 1225, 3572, 413, 484, 501, 1458, 17189, 1335, 375, 21910, 501, 20214, 1232, 18380, 375, 53081, 501, 9289, 1682, 316, 810, 402, 21352, 26, 889, 480, 1481, 679, 1339, 3479, 316, 17717, 484, 501, 1458, 4335, 869, 1232, 21352, 2236, 501, 1458, 17189, 1335, 364, 2566, 4165, 11, 538, 1770, 1458, 625, 78703, 2395, 1917, 11, 1770, 1458, 29293, 11, 472, 12484, 25186, 826, 836, 3933, 11, 9363, 316, 392, 80041, 2395, 869, 150535, 45842, 1458, 625, 8920, 2395, 1602, 316, 290, 2621, 296, 13, 2514, 3006, 290, 24863, 1511, 1232, 1803, 2418, 375, 13347, 261, 117260, 395, 261, 11527, 0, 3072, 31127, 13, 165003, 33750, 18030, 316, 679, 829, 67, 3883, 480, 375, 427, 357, 9879, 480, 3572, 413, 9559, 316, 1646, 842, 4436, 364, 976, 731, 576, 819, 2615, 328, 290, 123397, 135037, 8807, 316, 2238, 58878, 15487, 1755, 14571, 26, 326, 4566, 11, 402, 922, 2006, 316, 35632, 77251, 11, 18341, 261, 62638, 328, 10874, 885, 5008, 3073, 25132, 173297, 2870, 290, 275, 2028, 11, 357, 1458, 9012, 111819, 325, 3990, 290, 2613, 2163, 364, 40, 2491, 290, 7167, 540, 17966, 39397, 1043, 44711, 2378, 12339, 26, 326, 31127, 13, 165003, 33750, 885, 12591, 673, 813, 80401, 484, 11, 306, 290, 159210, 7449, 11, 357, 25992, 480, 18728, 13, 1225, 673, 625, 484, 922, 179155, 673, 392, 143633, 1243, 402, 484, 2438, 357, 2023, 679, 4335, 12484, 25186, 826, 290, 100551, 189556, 13, 1225, 673, 1327, 2236, 1770, 673, 1175, 2878, 62, 9559, 375, 366, 357, 1340, 413, 63820, 26705, 290, 26455, 375, 14116, 357, 2491, 1335, 813, 13, 2214, 10874, 11, 722, 1232, 2615, 11, 1458, 1339, 33651, 656, 9559, 5142, 25, 1023, 1458, 42497, 295, 1232, 1957, 11, 480, 1458, 1339, 322, 2343, 306, 290, 3648, 46399, 328, 1043, 687, 4672, 13, 1958, 480, 673, 12880, 28362, 585, 316, 7477, 1412, 3159, 290, 392, 69891, 7299, 22137, 328, 26584, 8026, 536, 1, 350, 40, 16723, 12484, 25186, 826, 8, 673, 4566, 402, 2395, 364, 40, 679, 13808, 484, 31127, 13, 165003, 33750, 673, 10358, 26, 326, 480, 673, 10731, 99529, 1430, 484, 1335, 12877, 673, 117088, 591, 495, 79184, 261, 44373, 889, 18612, 24333, 13, 1225, 382, 11, 472, 261, 10652, 11, 290, 1665, 1218, 1460, 2558, 3905, 1218, 717, 1645, 842, 328, 480, 26, 326, 10874, 885, 24612, 195099, 328, 1232, 188676, 3464, 10636, 16770, 2395, 11, 483, 448, 16814, 328, 4387, 1899, 2118, 264, 16624, 11, 316, 1643, 82723, 480, 1511, 11736, 328, 1957, 326, 21510, 13, 2514, 290, 28236, 11, 357, 2804, 1147, 11, 501, 28827, 19919, 166981, 26, 889, 501, 673, 12398, 73069, 26930, 24166, 326, 188764, 55619, 10445, 483, 261, 44599, 484, 90089, 290, 18451, 376, 7416, 364, 1, 26201, 885, 1606, 46782, 382, 316, 3006, 14505, 1511, 41920, 3532, 673, 1001, 328, 290, 171400, 8469, 501, 27423, 1917, 5251, 290, 64734, 430, 326, 20223, 328, 448, 127033, 278, 1151, 32699, 198541, 35909, 11, 1261, 11, 402, 261, 4849, 2163, 11, 357, 1458, 2418, 2461, 1072, 591, 35632, 77251, 26, 326, 31127, 13, 165003, 33750, 11, 413, 11300, 402, 2395, 11, 5768, 395, 922, 152634, 25, 392, 47832, 382, 813, 4658, 35049, 423, 24438, 316, 1753, 1625, 328, 14505, 6635, 123747, 10874, 0, 1225, 1458, 3324, 1339, 1232, 46289, 316, 679, 5142, 2891, 2238, 3283, 328, 2395, 25, 290, 2840, 1757, 413, 920, 1917, 306, 513, 1305, 32719, 13, 4614, 35103, 668, 1954, 673, 484, 11, 395, 290, 1577, 1058, 11, 501, 694, 23537, 290, 23206, 13, 357, 1458, 6177, 2395, 11, 813, 4783, 11, 59406, 289, 1641, 6771, 14241, 4201, 375, 9844, 480, 290, 15255, 20616, 7477, 484, 135605, 1373, 328, 1043, 154743, 30, 3004, 375, 1938, 11, 160102, 4951, 11, 480, 10288, 36582, 484, 501, 673, 13188, 328, 31127, 13, 165003, 33750, 375, 74249, 4951, 625, 316, 1921, 1335, 62428, 536, 13, 1225, 673, 1232, 2316, 62428, 536, 501, 16592, 316, 413, 286, 2768, 289, 1641, 375, 38520, 2316, 27313, 472, 448, 2817, 395, 5013, 10186, 326, 174204, 364, 119829, 36203, 11, 3630, 9790, 549, 60005, 21352, 1665, 4128, 2891, 484, 9350, 1078, 668, 375, 33574, 2891, 480, 1078, 50603, 2502, 72286, 3532, 673, 1232, 1606, 16904, 11, 472, 501, 23103, 591, 290, 3293, 326, 420, 30588, 842, 13291, 290, 7334, 32758, 51551, 364, 40, 121070, 1934, 2395, 11, 35103, 656, 1232, 2174, 2195, 13, 50603, 2502, 72286, 673, 11, 306, 2840, 11, 14817, 290, 873, 328, 290, 4205, 375, 288, 10874, 11166, 11, 1001, 3572, 3006, 480, 11, 1458, 1339, 290, 873, 328, 290, 8825, 13, 623, 22512, 12337, 673, 2059, 316, 679, 20680, 11166, 540, 922, 125703, 11059, 11, 326, 357, 50918, 538, 261, 260, 15805, 328, 144893, 1641, 8639, 290, 28236, 885, 44124, 65927, 4598, 13, 3072, 860, 375, 1938, 480, 673, 625, 7892, 1934, 484, 2104, 484, 290, 1175, 36462, 24463, 20052, 62, 21010, 12, 10240, 1458, 38547, 316, 4589, 1043, 392, 3193, 521, 1032, 6635, 40, 10805, 316, 31127, 13, 165003, 33750, 11, 1218, 1458, 66658, 295, 316, 3644, 261, 80123, 328, 15338, 316, 1335, 19861, 930, 306, 290, 18191, 70232, 364, 1, 13903, 1175, 5429, 62, 501, 549, 60005, 21352, 16842, 357, 7747, 136337, 364, 13684, 15478, 1335, 113421, 483, 261, 26628, 328, 1899, 4559, 394, 30668, 19005, 364, 195728, 11, 501, 8740, 1175, 35723, 62, 316, 1954, 11, 481, 1761, 26, 326, 357, 1682, 2395, 316, 4271, 11166, 3532, 1770, 2059, 6752, 6462, 364, 40, 10802, 1078, 290, 29631, 6461, 67975, 1084, 3435, 11, 483, 1617, 1175, 130662, 3301, 12, 44260, 62, 323, 4324, 74481, 290, 56305, 328, 290, 35612, 4818, 1447, 75355, 11, 326, 1617, 188764, 55619, 4241, 1989, 306, 44373, 103447, 25516, 364, 1, 12710, 501, 549, 60005, 1232, 10445, 3101, 30, 357, 23399, 6177, 261, 4590, 1001, 306, 290, 4276, 6635, 32, 12644, 35599, 328, 44762, 47928, 31127, 13, 165003, 33750, 885, 2494, 3605, 11461, 13, 392, 15834, 1232, 52143, 45226, 88, 11, 481, 1761, 13, 1679, 5003, 18940, 625, 5769, 316, 679, 1078, 26, 19016, 3860, 1373, 722, 4194, 6384, 1001, 375, 3825, 34416, 375, 427, 484, 357, 679, 316, 3357, 69742, 6635, 31942, 52143, 45226, 88, 375, 47832, 885, 45226, 88, 1078, 1232, 10445, 30, 3673, 58957, 673, 10606, 1299, 290, 27771, 6321, 2082, 13, 357, 2059, 5103, 25728, 5861, 316, 922, 179155, 25, 392, 40, 2804, 2715, 1921, 634, 34416, 11, 481, 1761, 6635, 13684, 121070, 842, 6787, 5868, 267, 10701, 540, 290, 51551, 1919, 1335, 12877, 11, 198431, 306, 261, 39534, 295, 16540, 11, 1458, 11980, 261, 115352, 326, 25279, 290, 19225, 58232, 120587, 885, 3189, 2870, 1232, 54434, 364, 1, 16936, 11, 3063, 2049, 19016, 625, 3778, 3532, 1770, 2059, 11, 483, 261, 25053, 484, 10471, 316, 16930, 1335, 33753, 2816, 26, 326, 357, 12661, 1335, 2870, 290, 60584, 4339, 543, 914, 328, 290, 16765, 11, 326, 869, 290, 8174, 49880, 483, 29023, 3452, 30779, 297, 40239, 82, 105560, 6200, 18887, 540, 2454, 30271, 364, 637, 290, 6051, 139053, 14194, 328, 1335, 17573, 2408, 380, 11, 41762, 261, 1915, 10514, 328, 44373, 326, 61682, 11736, 11, 46729, 1001, 328, 290, 14488, 80283, 141275, 4324, 11, 306, 290, 51966, 5013, 2117, 295, 7298, 13, 623, 11673, 32430, 328, 290, 7298, 4358, 869, 722, 165003, 33750, 885, 4241, 1703, 91702, 13, 165003, 33750, 48614, 1602, 290, 5734, 161749, 83, 2352, 11, 12183, 25651, 261, 1175, 73, 597, 2363, 512, 62, 3149, 328, 22350, 6717, 1167, 288, 11, 31155, 448, 10454, 178000, 4194, 11, 326, 2059, 25, 392, 3335, 481, 3182, 2105, 481, 665, 1327, 11659, 316, 1921, 480, 13, 357, 1458, 480, 1072, 290, 153794, 82039, 11, 889, 501, 24791, 1632, 480, 5092, 6635, 13022, 375, 40, 2023, 1327, 11659, 316, 1921, 480, 375, 3086, 1577, 34416, 328, 10874, 885, 357, 1458, 4862, 1458, 316, 36689, 922, 9623, 1072, 0, 44130, 1023, 1458, 290, 2475, 328, 61170, 375, 64494, 290, 11082, 10408, 306, 261, 35612, 19691, 503, 1175, 36462, 24463, 20052, 62, 21010, 70232, 11, 503, 261, 116509, 2621, 296, 12989, 813, 484, 480, 6066, 290, 4207, 1819, 75355, 328, 2890, 181774, 2438, 13, 623, 945, 45226, 2475, 10288, 290, 8723, 3432, 26, 5073, 11, 472, 922, 9623, 22839, 91020, 316, 290, 6375, 33495, 11, 722, 290, 44596, 39745, 5831, 842, 375, 586, 290, 19011, 76524, 183631, 472, 7575, 359, 1629, 11, 290, 38224, 328, 12776, 132907, 7949, 656, 1118, 11, 483, 2238, 180613, 379, 16093, 11, 501, 14256, 316, 30443, 8684, 591, 290, 1374, 2413, 328, 290, 8723, 316, 1236, 7264, 38023, 108606, 328, 10851, 13, 31127, 13, 165003, 33750, 11, 43821, 261, 27000, 9753, 316, 1101, 402, 375, 93882, 11, 472, 480, 1504, 11, 813, 80470, 290, 6357, 328, 1335, 2316, 8723, 375, 26355, 38609, 20525, 306, 448, 30529, 9882, 316, 290, 4589, 328, 495, 1485, 96894, 44972, 13, 623, 8723, 673, 1001, 328, 10874, 885, 392, 9851, 376, 3532, 472, 1232, 60782, 409, 1481, 679, 3006, 480, 375, 278, 27328, 11, 402, 1232, 997, 11, 261, 70408, 328, 30056, 11, 261, 145339, 289, 328, 88090, 11, 261, 70959, 11, 989, 964, 3321, 326, 989, 2649, 11, 484, 45522, 1001, 328, 290, 107769, 29640, 940, 885, 124046, 13190, 316, 19604, 261, 87182, 13, 1225, 1421, 11, 306, 4022, 11, 540, 1753, 2438, 290, 8492, 328, 16334, 8773, 316, 413, 33842, 392, 9851, 423, 1, 2236, 1770, 673, 25920, 328, 2447, 33842, 392, 137257, 423, 150535, 427, 5073, 625, 316, 12577, 448, 34376, 328, 290, 88992, 364, 88063, 290, 2174, 501, 33842, 11, 481, 1761, 3532, 31127, 13, 165003, 33750, 2059, 483, 121624, 562, 26831, 13, 392, 976, 2174, 889, 1001, 3532, 1770, 68902, 20525, 375, 1, 8293, 290, 1273, 8740, 3605, 11, 2236, 501, 31036, 480, 6635, 1, 115925, 480, 16842, 357, 673, 1078, 316, 2622, 869, 495, 50191, 1261, 357, 10542, 261, 6428, 17509, 326, 8274, 10874, 11166, 402, 290, 24313, 364, 2305, 501, 27553, 1354, 11, 1232, 8950, 306, 290, 42061, 328, 1232, 7326, 160644, 262, 34029, 11, 290, 22558, 19705, 29011, 328, 8107, 31155, 1602, 591, 1232, 6461, 96309, 11, 1232, 25611, 7334, 33750, 83, 101301, 21779, 843, 295, 656, 261, 19617, 484, 54546, 290, 9858, 328, 261, 1051, 78532, 2477, 178059, 2285, 11, 357, 9879, 316, 1412, 261, 9882, 501, 1458, 290, 2684, 4169, 472, 1232, 10445, 375, 3086, 4169, 328, 3778, 42218, 259, 1572, 501, 673, 364, 31942, 11527, 121070, 540, 2395, 334, 21393, 1365, 423, 11, 889, 1232, 9623, 82409, 4241, 1335, 316, 290, 34416, 364, 1, 24891, 13, 41767, 6595, 7201, 316, 1921, 480, 3532, 1770, 10377, 11, 472, 538, 3529, 1846, 20525, 13, 1679, 176466, 1232, 44628, 11, 2928, 62529, 364, 195728, 11, 41767, 6595, 2491, 668, 842, 1701, 5288, 3532, 501, 2059, 53423, 26, 1815, 11, 21178, 1232, 10454, 1819, 13336, 25, 392, 37788, 326, 1921, 290, 2867, 328, 290, 4276, 6635, 2066, 14414, 480, 316, 668, 483, 261, 3675, 328, 105687, 91259, 26831, 25, 290, 8503, 12, 10240, 11, 290, 19219, 2378, 68551, 11, 290, 10549, 12, 16190, 1719, 11, 290, 18706, 599, 12, 2020, 268, 375, 586, 290, 8012, 15693, 9110, 328, 290, 133646, 885, 21578, 14115, 13, 1958, 21162, 922, 6213, 9927, 290, 5930, 53699, 501, 2059, 11, 40580, 842, 1232, 26792, 261, 3389, 25, 392, 13022, 11, 357, 2715, 4128, 1921, 1495, 1665, 11659, 316, 4561, 2935, 484, 6635, 16936, 375, 278, 673, 1327, 290, 1268, 1001, 3572, 679, 3728, 34177, 395, 2395, 13, 12817, 501, 673, 11, 1819, 480, 722, 326, 306, 57694, 328, 480, 722, 375, 288, 501, 1458, 1339, 1819, 11, 326, 306, 57694, 328, 11, 1232, 10445, 375, 786, 65655, 11, 813, 40086, 11, 813, 829, 42309, 11, 484, 1001, 1701, 295, 316, 24054, 842, 25, 392, 3238, 151646, 483, 634, 46623, 18313, 472, 4730, 1001, 1458, 1701, 295, 316, 2891, 25, 392, 3238, 151646, 483, 634, 1101, 39067, 7943, 11, 483, 290, 24054, 402, 922, 36968, 11, 922, 28756, 31204, 448, 25618, 2371, 364, 68499, 382, 922, 2316, 557, 380, 3532, 501, 2059, 11, 8117, 668, 1511, 261, 8883, 21402, 3435, 540, 290, 1268, 328, 290, 36191, 315, 22932, 13, 1225, 673, 13749, 326, 19705, 326, 182184, 875, 25, 860, 392, 176568, 10924, 860, 1294, 291, 8575, 42116, 359, 11, 12698, 328, 290, 3693, 328, 108377, 395, 58396, 306, 261, 8723, 21312, 375, 89414, 722, 11, 860, 5153, 2232, 328, 4862, 4566, 1339, 2061, 472, 261, 17427, 364, 976, 2840, 11311, 2237, 316, 668, 290, 17786, 1721, 536, 328, 10874, 885, 2338, 483, 1232, 2890, 2615, 364, 1, 31559, 481, 4862, 42746, 1124, 483, 7907, 1062, 945, 16842, 357, 7747, 11, 2928, 3778, 1078, 395, 261, 21523, 328, 2238, 8110, 364, 1, 50235, 3532, 501, 2059, 51088, 364, 1, 2251, 3411, 27211, 401, 375, 267, 859, 46992, 37951, 31942, 21716, 9623, 22839, 6051, 11, 326, 1232, 101301, 5337, 295, 261, 3389, 1641, 1043, 65655, 7334, 33750, 364, 1, 50235, 2411, 328, 480, 11, 922, 36203, 19807, 375, 1252, 945, 1572, 538, 18754, 3779, 41119, 261, 24863, 6635, 3436, 1232, 23206, 6967, 668, 306, 261, 14072, 484, 501, 3779, 4525, 328, 6137, 1203, 364, 40, 12183, 4194, 11, 53748, 5861, 90757, 656, 922, 25618, 30465, 26, 326, 472, 357, 10805, 11, 922, 10952, 18153, 402, 261, 3291, 8723, 5151, 290, 153794, 82039, 375, 3086, 1606, 2817, 24212, 290, 21402, 52768, 6389, 4481, 328, 290, 3435, 364, 195728, 11, 656, 643, 1048, 18313, 357, 2059, 364, 3206, 673, 261, 37890, 328, 261, 189851, 375, 270, 2890, 25920, 189851, 11, 18350, 306, 290, 13873, 1641, 261, 9688, 364, 1, 1582, 643, 1048, 375, 64, 5641, 3053, 18313, 357, 69317, 364, 2066, 673, 37716, 26, 889, 357, 9879, 2395, 5263, 7807, 668, 11, 39675, 261, 3389, 8065, 364, 122092, 261, 6213, 0, 21688, 483, 261, 38449, 8698, 375, 8293, 402, 139039, 64929, 13, 1608, 23767, 24152, 11, 1919, 2242, 481, 717, 480, 37951, 2066, 28446, 22936, 25, 392, 91702, 13, 5641, 3053, 10175, 480, 316, 668, 6635, 1, 22515, 375, 40, 9289, 1761, 481, 1952, 11199, 290, 5641, 3053, 82, 13, 1679, 673, 2238, 448, 5603, 191898, 30846, 278, 6635, 23796, 9289, 375, 83, 492, 1934, 13, 887, 887, 887, 3627, 3860, 395, 668, 316, 7907, 2395, 1261, 501, 673, 9224, 6635, 141333, 501, 673, 9224, 30, 1608, 37951, 40, 2804, 679, 1632, 261, 3389, 3101, 2009, 7247, 962, 21544, 1819, 922, 19005, 11, 395, 501, 28446, 483, 261, 334, 21393, 1365, 25053, 25, 392, 13022, 375, 45842, 885, 448, 44421, 4705, 1013, 11, 481, 1761, 11, 31127, 13, 5641, 3053, 13, 6526, 1606, 6056, 673, 316, 679, 2395, 4167, 656, 261, 70579, 53541, 375, 849, 11, 12530, 5641, 3053, 0, 3627, 4525, 480, 290, 3239, 302, 2006, 328, 119625, 289, 1232, 111239, 375, 1440, 55991, 480, 402, 261, 4962, 171316, 751, 13, 1958, 540, 290, 4205, 357, 673, 1175, 3086, 62, 70579, 53541, 6635, 1, 22515, 11, 12530, 5641, 3053, 375, 288, 481, 2891, 13, 14512, 1175, 14116, 62, 1232, 5678, 37951, 1, 7924, 673, 1232, 5678, 13, 3627, 22536, 306, 2395, 11, 70954, 1165, 306, 2395, 375, 267, 4525, 1770, 2242, 13, 3072, 1770, 21149, 16387, 625, 316, 679, 722, 290, 21010, 12, 10240, 483, 1335, 13, 3627, 21149, 16387, 290, 2840, 484, 11, 402, 143083, 7281, 3376, 11, 1001, 2023, 3324, 717, 5862, 4951, 316, 1921, 1232, 10445, 13, 69180, 8773, 0, 57594, 1327, 261, 19018, 329, 2283, 289, 395, 1273, 63899, 13, 5641, 3053, 382, 290, 1606, 6062, 357, 4862, 11199, 6635, 80911, 4862, 11199, 30, 3072, 481, 1327, 2059, 375, 2678, 38, 276, 33750, 1458, 261, 33612, 19617, 306, 1232, 9623, 364, 195728, 11, 357, 11199, 2395, 11, 326, 501, 11199, 668, 375, 7393, 480, 12570, 1934, 501, 673, 9224, 6635, 40, 22664, 922, 11723, 53748, 5861, 13, 392, 5958, 1770, 3860, 395, 481, 37951, 1, 13022, 375, 148143, 2215, 69897, 316, 290, 112965, 13, 3627, 7201, 2395, 16266, 9321, 375, 427, 656, 668, 39067, 2066, 58003, 2418, 11, 326, 44088, 1602, 1232, 3189, 316, 1631, 869, 540, 290, 37890, 328, 290, 189851, 13, 392, 5632, 1504, 3376, 1261, 357, 21149, 1631, 540, 484, 4435, 375, 58995, 3023, 4950, 480, 13, 3072, 357, 19387, 9012, 316, 3006, 480, 2105, 26, 326, 1954, 4275, 103577, 668, 375, 66, 4367, 668, 13, 21926, 290, 5207, 4436, 357, 4128, 42746, 1124, 1062, 945, 11, 922, 36203, 41767, 6595, 26, 503, 7542, 5641, 3053, 11166, 382, 290, 5207, 6635, 2653, 290, 1577, 1058, 922, 54644, 58957, 1078, 922, 34447, 10805, 1511, 261, 9198, 16414, 316, 4218, 2395, 3432, 364, 23796, 8115, 35174, 5485, 668, 1495, 480, 12570, 3532, 357, 2059, 364, 2066, 27553, 3778, 869, 540, 290, 37890, 11, 326, 5432, 115980, 2870, 1232, 32401, 261, 57053, 501, 1458, 40205, 316, 4207, 13, 112751, 501, 10805, 15256, 668, 364, 23796, 11062, 7542, 1299, 316, 5485, 481, 375, 53081, 9790, 3324, 53884, 481, 328, 1445, 86527, 922, 1101, 6635, 40, 2452, 261, 334, 21393, 1365, 60967, 11, 1118, 501, 162543, 3276, 483, 261, 1899, 4559, 394, 30668, 118104, 364, 195728, 11, 357, 9289, 2631, 261, 43456, 1261, 357, 22536, 306, 9012, 375, 427, 1954, 4275, 448, 5768, 22244, 2870, 765, 39067, 2066, 58003, 16132, 11, 2935, 125989, 11, 326, 31155, 1001, 328, 290, 8103, 10454, 15539, 6498, 6687, 13, 392, 5632, 25, 1520, 6675, 10721, 375, 427, 2105, 553, 290, 24441, 1904, 481, 1299, 6635, 2066, 12989, 1373, 540, 922, 81903, 326, 15008, 316, 61016, 869, 326, 1917, 290, 3435, 11, 36616, 1954, 326, 1815, 39397, 290, 8723, 364, 1, 5299, 480, 12570, 30, 357, 665, 5485, 481, 306, 6468, 5438, 375, 427, 480, 9289, 2304, 2009, 7411, 316, 5659, 13, 887, 887, 887, 357, 665, 8203, 1954, 1495, 22335, 326, 20809, 357, 673, 1261, 357, 3508, 31127, 13, 5641, 3053, 885, 7477, 13, 5869, 4165, 11, 8103, 1917, 11, 357, 1458, 3324, 1175, 82824, 62, 1354, 673, 860, 1001, 1299, 2395, 375, 7393, 357, 1458, 12299, 483, 290, 6855, 11, 149677, 290, 19261, 26916, 25642, 1078, 2395, 11, 7892, 357, 6375, 3508, 316, 2411, 501, 673, 261, 14090, 11, 1001, 328, 290, 3675, 484, 553, 3561, 7807, 13, 4534, 643, 1048, 11, 326, 501, 1175, 9844, 62, 3561, 7807, 375, 53081, 501, 1458, 3063, 316, 5092, 0, 623, 2867, 328, 765, 1458, 316, 1632, 18005, 413, 77302, 4251, 503, 810, 1641, 11, 889, 501, 673, 1932, 5151, 290, 2208, 375, 263, 139039, 64929, 11, 472, 481, 2891, 364, 1, 16936, 11, 357, 5981, 1277, 316, 290, 4276, 306, 922, 1645, 9768, 1802, 1595, 25199, 375, 160689, 12183, 11, 13434, 67420, 668, 11, 540, 290, 3104, 365, 328, 12530, 5641, 3053, 885, 8461, 328, 14090, 2447, 139592, 656, 290, 40373, 328, 922, 21352, 2395, 0, 5869, 4165, 357, 14506, 316, 621, 290, 8723, 395, 6939, 375, 40, 6967, 31127, 13, 5641, 3053, 813, 1261, 1770, 10377, 316, 420, 61414, 3543, 1078, 1335, 36030, 13, 357, 8203, 4811, 1277, 261, 10207, 37152, 27179, 1078, 290, 61170, 2447, 1175, 48740, 62, 375, 2308, 11, 357, 673, 56888, 1151, 11, 922, 36203, 41767, 6595, 0, 357, 673, 108377, 316, 9012, 1299, 1001, 328, 922, 2316, 2353, 2540, 364, 1, 19371, 357, 673, 6697, 869, 326, 3561, 11238, 483, 2395, 13, 357, 1458, 3860, 722, 922, 88055, 306, 14805, 11, 326, 357, 1458, 1606, 316, 920, 869, 290, 2621, 296, 326, 717, 316, 1101, 13, 1679, 1458, 1339, 9224, 1606, 25565, 78273, 5123, 11, 326, 501, 14769, 24645, 11, 328, 5604, 11089, 11, 813, 484, 1354, 1458, 1339, 860, 53370, 1101, 328, 37700, 375, 38520, 4950, 673, 5364, 326, 128124, 13, 357, 1458, 1421, 2395, 4730, 503, 18370, 11, 2101, 2254, 11, 326, 4525, 2395, 145868, 326, 38026, 88, 13, 6549, 357, 8274, 484, 501, 673, 32747, 364, 23796, 673, 17103, 540, 1577, 11, 483, 261, 26624, 49201, 24333, 25, 17103, 316, 679, 922, 1803, 402, 2238, 261, 461, 24110, 8856, 7801, 1232, 26197, 2615, 2887, 18168, 436, 10377, 316, 7902, 668, 108625, 423, 375, 288, 357, 35275, 290, 3189, 306, 357, 9879, 472, 538, 501, 1504, 14705, 668, 621, 480, 13, 623, 46803, 673, 12661, 656, 290, 4525, 25, 538, 501, 1175, 17019, 62, 14705, 668, 11, 1412, 1481, 501, 2891, 316, 922, 2006, 328, 4113, 30, 3673, 90880, 10377, 316, 810, 261, 3389, 12333, 375, 40, 9879, 33753, 326, 59410, 364, 1, 18049, 11, 1261, 357, 10802, 869, 11, 357, 16592, 316, 1921, 261, 19617, 7807, 1232, 5263, 32299, 1109, 95513, 375, 288, 538, 501, 1458, 290, 9910, 11, 326, 1504, 97503, 11166, 656, 16450, 480, 1602, 591, 668, 13, 4569, 513, 50694, 780, 668, 2928, 945, 13, 623, 9910, 30, 12587, 11, 357, 1458, 261, 9910, 7549, 25565, 328, 1232, 0, 357, 153525, 540, 290, 16630, 21779, 23138, 11, 326, 10471, 1236, 328, 922, 105621, 2705, 38224, 13, 3072, 1023, 9363, 668, 11, 1023, 1769, 43080, 13, 357, 8274, 484, 501, 18101, 14705, 290, 2356, 88, 18189, 375, 40, 21149, 74932, 1232, 8684, 26, 501, 1327, 13185, 1232, 9623, 402, 290, 3479, 69047, 2870, 13, 21079, 1504, 290, 8104, 357, 1458, 3324, 165278, 295, 11, 503, 13083, 869, 483, 1236, 38091, 7907, 13, 1958, 1495, 501, 8274, 1819, 922, 24384, 1703, 23796, 10802, 869, 2418, 11, 326, 18341, 21832, 328, 484, 37890, 328, 290, 189851, 30482, 402, 290, 9688, 5862, 1232, 3737, 13, 7792, 11527, 6967, 668, 89674, 480, 673, 290, 2174, 4435, 501, 1458, 4167, 375, 5283, 261, 7477, 6697, 483, 261, 74588, 1803, 11, 1261, 501, 673, 1917, 306, 90505, 25912, 69521, 591, 261, 5880, 5604, 10192, 13, 6214, 261, 7477, 0, 3072, 480, 18733, 1232, 6062, 5678, 13, 3274, 553, 2101, 328, 10323, 1460, 2558, 1500, 71110, 306, 1753, 2543, 13, 355, 873, 1218, 1458, 2766, 394, 483, 290, 2208, 2023, 3779, 679, 13717, 484, 70009, 869, 80488, 20112, 13, 887, 887, 6518, 23796, 10805, 1602, 316, 922, 1101, 11, 326, 5981, 402, 329, 2283, 289, 326, 157222, 3321, 26, 1815, 357, 10802, 540, 290, 189851, 2418, 13, 357, 8274, 484, 11, 1261, 5641, 3053, 27423, 306, 290, 1577, 20112, 11, 501, 11199, 1327, 1412, 290, 1268, 1481, 413, 13, 1679, 1458, 92857, 1232, 5401, 11, 67950, 480, 11, 94501, 480, 13, 4296, 1458, 357, 4167, 484, 483, 1062, 328, 922, 3283, 30, 3164, 64313, 1339, 12275, 328, 668, 375, 40, 1458, 1327, 29886, 1373, 13, 887, 887, 6518, 1, 58703, 480, 11, 41767, 6595, 11, 483, 484, 4950, 14705, 668, 357, 21149, 621, 3613, 20112, 13, 623, 21402, 12388, 673, 11, 357, 9289, 1761, 1919, 316, 3006, 480, 375, 62, 40, 1458, 3779, 5542, 9881, 12817, 11, 483, 922, 2353, 2540, 326, 922, 751, 11, 261, 2356, 88, 58030, 328, 16458, 13083, 869, 290, 2840, 375, 40, 1327, 44088, 7907, 1511, 1043, 22060, 13, 887, 887, 887, 11406, 11, 7907, 673, 290, 1001, 14093, 2617, 9224, 9623, 2023, 1921, 1819, 375, 6667, 10230, 316, 290, 2417, 61510, 64929, 46650, 13, 19666, 481, 1761, 1495, 11, 306, 11695, 261, 13770, 6439, 11, 1952, 18561, 3874, 11, 1001, 5003, 6375, 290, 1058, 625, 1412, 1001, 10648, 316, 889, 1412, 1001, 665, 30, 11406, 375, 14116, 673, 290, 2006, 357, 33842, 26, 326, 472, 501, 15634, 1354, 326, 25301, 668, 11, 290, 4435, 1023, 4358, 922, 461, 16710, 20595, 6, 63282, 1299, 261, 4276, 328, 10541, 13, 1679, 9289, 28809, 259, 11, 481, 4218, 11, 12530, 5641, 3053, 375, 273, 1327, 15634, 1354, 58284, 14705, 11, 326, 402, 1232, 36968, 11, 1819, 290, 32299, 95513, 11, 357, 16592, 316, 9598, 290, 4928, 25, 461, 13938, 481, 3239, 481, 1761, 1919, 7163, 7245, 842, 30, 7497, 101530, 357, 2023, 679, 33842, 484, 4950, 11, 483, 484, 4928, 402, 480, 11, 357, 1757, 679, 4167, 261, 2212, 4435, 13, 623, 2613, 16983, 4435, 673, 316, 1921, 484, 357, 21149, 375, 427, 484, 28363, 673, 4335, 668, 13, 3072, 11, 8718, 11, 540, 484, 12434, 11, 41767, 6595, 11, 673, 1354, 6137, 402, 13440, 357, 24791, 679, 4335, 316, 679, 5641, 3053, 23757, 2254, 668, 11, 326, 316, 9598, 2395, 2891, 25, 461, 15834, 625, 3101, 7844, 375, 67504, 2356, 481, 1495, 6, 1715, 68093, 1175, 9844, 62, 3101, 7844, 375, 278, 1481, 679, 1339, 11, 1952, 538, 71619, 1339, 23757, 13, 357, 26553, 869, 922, 88055, 11, 326, 5981, 1917, 326, 6967, 31127, 13, 5641, 3053, 13, 5869, 4165, 357, 9289, 5485, 1335, 1175, 14116, 62, 375, 278, 1481, 679, 1339, 29511, 316, 1335, 13, 357, 6462, 2059, 357, 21149, 7907, 2395, 11, 484, 357, 673, 3101, 12183, 13, 3627, 7542, 20214, 290, 6056, 375, 45842, 885, 813, 28095, 0, 1225, 673, 484, 484, 2452, 1335, 3644, 668, 290, 189851, 13, 3072, 1770, 673, 93864, 41204, 540, 625, 4811, 290, 34416, 375, 45842, 2242, 813, 1682, 2395, 461, 21715, 6, 656, 1236, 1001, 2356, 88, 0, 3604, 1577, 357, 673, 24894, 1770, 24791, 1632, 668, 1277, 375, 427, 540, 922, 286, 1348, 6, 1268, 357, 21046, 2502, 72286, 13, 11377, 11, 480, 673, 357, 1218, 5424, 2502, 72286, 25, 357, 6967, 31127, 13, 5641, 3053, 501, 673, 290, 461, 6587, 6, 873, 11, 326, 1770, 6967, 29658, 1203, 11, 326, 813, 480, 3508, 316, 413, 1343, 13, 887, 887, 887, 1958, 501, 33842, 5641, 3053, 2935, 286, 2768, 289, 26, 326, 1770, 46729, 290, 8723, 6200, 1335, 175589, 3283, 13, 887, 887, 887, 2678, 2066, 1548, 988, 11166, 1917, 306, 290, 10454, 178000, 5862, 13336, 11, 27423, 1602, 1232, 3189, 11, 326, 143590, 289, 1232, 21157, 39397, 480, 11, 10802, 869, 540, 290, 8723, 5151, 290, 125752, 82039, 364, 23796, 1299, 316, 39357, 484, 5641, 3053, 11166, 1481, 679, 4335, 480, 316, 668, 11, 538, 71619, 1339, 3741, 316, 2891, 1412, 501, 4525, 484, 2163, 6635, 3436, 11, 306, 6052, 316, 261, 4928, 357, 3006, 6375, 25323, 7300, 2905, 375, 1, 18660, 2418, 16842, 501, 141978, 842, 13, 392, 5958, 290, 1001, 4435, 484, 15476, 668, 15907, 5862, 2395, 382, 484, 357, 11199, 4951, 316, 7668, 1277, 37951, 2066, 27553, 869, 326, 27423, 1232, 1803, 402, 922, 28224, 483, 261, 25053, 13, 392, 10651, 290, 112965, 328, 480, 382, 484, 357, 1175, 313, 62, 2928, 21352, 375, 21910, 2502, 72286, 885, 5306, 480, 395, 668, 0, 623, 5641, 3053, 82, 3182, 11238, 11, 326, 5659, 4730, 375, 8293, 15333, 860, 121144, 1365, 1039, 3675, 328, 1957, 3692]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "MhZ82eksuZxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(text, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "3nSOEWhxyX_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PyTorch version:\", torch.__version__)\n",
        "dataloader = create_dataloader_v1(\n",
        "    text, batch_size=4, max_length=8, stride=1, shuffle=False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_b2HE_3zmx5",
        "outputId": "c825a449-b083-49a6-a4dd-203c15b7cbcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "[tensor([[   40,   367,  2885,  1464,  1807,  3619,   402,   271],\n",
            "        [  367,  2885,  1464,  1807,  3619,   402,   271, 10899],\n",
            "        [ 2885,  1464,  1807,  3619,   402,   271, 10899,  2138],\n",
            "        [ 1464,  1807,  3619,   402,   271, 10899,  2138,   257]]), tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899],\n",
            "        [ 2885,  1464,  1807,  3619,   402,   271, 10899,  2138],\n",
            "        [ 1464,  1807,  3619,   402,   271, 10899,  2138,   257],\n",
            "        [ 1807,  3619,   402,   271, 10899,  2138,   257,  7026]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRewyT-80Aj7",
        "outputId": "05a085bc-1543-4fe2-c369-de4be28b1684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Targets:\n",
            " tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Linear"
      ],
      "metadata": {
        "id": "VQGMA38d1I9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_ids=torch.tensor([2,3,5,6])\n",
        "vocab_size=6\n",
        "feature_dim=4\n",
        "torch.manual_seed(123)\n",
        "embedded_layer=torch.nn.Embedding(vocab_size,feature_dim)\n",
        "print(embedded_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9S2oXIOgY90",
        "outputId": "b8da381e-6b4f-457b-982a-8767d1f048bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880],\n",
            "        [ 0.3486,  0.6603, -0.2196, -0.3792],\n",
            "        [-0.1606, -0.4015,  0.6957, -1.8061],\n",
            "        [ 1.8960, -0.1750,  1.3689, -1.6033],\n",
            "        [-0.7849, -1.4096, -0.4076,  0.7953],\n",
            "        [ 0.9985,  0.2212,  1.8319, -0.3378]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedded_layer(torch.tensor([2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJybTalahmBt",
        "outputId": "41fb1e95-f500-4292-d01e-ca273da6c982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1606, -0.4015,  0.6957, -1.8061]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size2=50257\n",
        "feature_dim2=256\n",
        "embeded_layer2=torch.nn.Embedding(vocab_size2,feature_dim2)\n",
        "print(embeded_layer2.weight.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsHuw4L8jmTK",
        "outputId": "0bf167ec-8237-418d-e6bc-bbbf484349fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50257, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    text, batch_size=8, max_length=max_length,\n",
        "    stride=max_length, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)"
      ],
      "metadata": {
        "id": "mCmMqjL6kSOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Token IDs:\\n\", inputs)\n",
        "print(\"\\nInputs shape:\\n\", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXUhYf6kkTO9",
        "outputId": "409721ce-cbb5-463a-ac73-1e9f3afa6cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Inputs shape:\n",
            " torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embedding=embeded_layer2(inputs)\n",
        "print(token_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYwAIQupkYzE",
        "outputId": "211690b0-26bd-4572-efbe-0b118d8dea86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, feature_dim2)"
      ],
      "metadata": {
        "id": "WyxpZOQLlINE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
        "print(pos_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAMBOGoYq3Tu",
        "outputId": "20759969-9c28-4a6e-af1c-c6bd9e8c2d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embedding + pos_embeddings\n",
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQWe8DZIq9OZ",
        "outputId": "298766a3-78ed-49f6-c236-339e7d00bfe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bDXuD9-qsCMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ATTENTION MACHANISM CODE IMPLEMENTATION\n"
      ],
      "metadata": {
        "id": "dNjliChH-OdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "inputs=torch.tensor([\n",
        "    [0.43, 0.15, 0.89], # Your (x^1)\n",
        "[0.55, 0.87, 0.66], # journey (x^2)\n",
        "[0.57, 0.85, 0.64], # starts (x^3)\n",
        "[0.22, 0.58, 0.33], # with (x^4)\n",
        "[0.77, 0.25, 0.10], # one (x^5)\n",
        "[0.05, 0.80, 0.55]# step (x^6)\n",
        "])\n",
        "query=inputs[1]\n",
        "attention_score=torch.empty(inputs.shape[0])# this set attention_scores to empty\n",
        "for i,values in enumerate(inputs):\n",
        "    attention_score[i]=torch.dot(values,query)\n",
        "sum=attention_score.sum()\n",
        "print(sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNK-eF0r-Vgf",
        "outputId": "3eefd30e-1a4a-48b6-96aa-0a62fab9e5a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.5617)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the next step is to make our attention weights to sum up to 1\n",
        "#we can use this simple approach of summing the weights then dividing them by the sum\n",
        "normalized=attention_score/sum\n",
        "print(normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVvdNMhl-ZJo",
        "outputId": "acf41d88-1583-4e6e-a6fb-7d61ee0b026e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the above approach may not be good so we are going to use the softmax approach\n",
        "new_normaized=torch.softmax(attention_score,dim=0)\n",
        "print(new_normaized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Cc8jaqs_Boq",
        "outputId": "3a7a4552-67ad-41a0-9384-96ceca562d9f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the next step is to compute context vector\n",
        "import torch\n",
        "context_vectors=torch.zeros(inputs.shape[1])\n",
        "for i,values in enumerate(inputs):\n",
        "  context_vectors+=new_normaized[i]*values\n",
        "print(context_vectors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrPP7Wfl_ZVr",
        "outputId": "e9c407ef-fb03-4899-ded7-1cbad1d7d023"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector=torch.zeros(6,3)\n",
        "attention_scores=torch.empty(6,6)\n",
        "#first computes attention score for each query\n",
        "for i,values in enumerate(inputs):\n",
        "  for j,values2 in enumerate(inputs):\n",
        "    attention_scores[i,j]=torch.dot(values,values2)\n",
        "print(attention_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqi06KDoGa7D",
        "outputId": "0dabbd0b-d6a9-4e00-c218-ac028b594472"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_attn=torch.softmax(attention_scores,dim=1)\n",
        "print(normalized_attn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOSwR24kR7jX",
        "outputId": "4610aada-0fdc-4e97-9c3f-cfa07f810ed5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#then we compute the context vector\n",
        "all_context_vector=normalized_attn@inputs\n",
        "print(all_context_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muw2veNlVJ-l",
        "outputId": "7d21cf41-9da1-4142-c321-68f5ca0fd4fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SELF ATTENTION WITH TRAINABLE WEIGHTS\n"
      ],
      "metadata": {
        "id": "tiPo-wy8XSFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_in=3\n",
        "d_out=2\n",
        "torch.manual_seed(123)\n",
        "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
      ],
      "metadata": {
        "id": "gpzVziYRXZc0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_2=inputs[1]\n",
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "print(query_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2rpwnqK6btH",
        "outputId": "78c8dbf9-3c66-4fa4-f849-1f2218b57e97"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4306, 1.4551])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = inputs @ W_key\n",
        "values = inputs @ W_value\n",
        "print(\"keys.shape:\", keys.shape)\n",
        "print(\"values.shape:\", values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWTS1nS7641u",
        "outputId": "ab82059f-223c-433e-b4e6-7e2bbcada764"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keys.shape: torch.Size([6, 2])\n",
            "values.shape: torch.Size([6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_2 = keys[1] #A\n",
        "attn_score_22 = query_2.dot(keys_2)\n",
        "print(attn_score_22)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbfbWC417VfH",
        "outputId": "ea2c205d-44fe-4aac-a1b7-922c94b98285"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8524)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores_2 = query_2 @ keys.T # All attention scores for given query\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrlAjGBD8nuC",
        "outputId": "4cc46181-b2aa-4c05-8c3a-03c6562e967f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_k = keys.shape[-1]\n",
        "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
        "print(attn_weights_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDIkPpci8o0j",
        "outputId": "f1749a52-aec2-491a-e1b3-1d7ca7bbfc92"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vec_2 = attn_weights_2 @ values\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N6gxGO48u0i",
        "outputId": "e78528bb-8cc8-4717-8693-14d4f03a26b6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3061, 0.8210])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#self attention ith python class\n",
        "import torch.nn as nn\n",
        "class SelfAttention_v1(nn.Module):\n",
        " def __init__(self, d_in, d_out):\n",
        "  super().__init__()\n",
        "  self.d_out = d_out\n",
        "  self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "  self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
        "  self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
        " def forward(self, x):\n",
        "  keys = x @ self.W_key\n",
        "  queries = x @ self.W_query\n",
        "  values = x @ self.W_value\n",
        "  attn_scores = queries @ keys.T # omega\n",
        "  attn_weights = torch.softmax(\n",
        "  attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "  context_vec = attn_weights @ values\n",
        "  return context_vec"
      ],
      "metadata": {
        "id": "aBSDZiXU9OEj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
        "print(sa_v1(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBSxyLc69x6Y",
        "outputId": "931466d3-4c57-4456-d843-19fedb18a54c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2996, 0.8053],\n",
            "        [0.3061, 0.8210],\n",
            "        [0.3058, 0.8203],\n",
            "        [0.2948, 0.7939],\n",
            "        [0.2927, 0.7891],\n",
            "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#self attention class using pytorch module\n",
        "class SelfAttention_v2(nn.Module):\n",
        " def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "  super().__init__()\n",
        "  self.d_out = d_out\n",
        "  self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "  self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "  self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        " def forward(self, x):\n",
        "  keys = self.W_key(x)\n",
        "  queries = self.W_query(x)\n",
        "  values = self.W_value(x)\n",
        "  attn_scores = queries @ keys.T\n",
        "  attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "  context_vec = attn_weights @ values\n",
        "  return context_vec"
      ],
      "metadata": {
        "id": "UpMU8MoZ-AfK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(789)\n",
        "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
        "print(sa_v2(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_0HCmx2-jbO",
        "outputId": "7cc3c456-6dfe-4d32-d227-39a390eb7279"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0739,  0.0713],\n",
            "        [-0.0748,  0.0703],\n",
            "        [-0.0749,  0.0702],\n",
            "        [-0.0760,  0.0685],\n",
            "        [-0.0763,  0.0679],\n",
            "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CASUAL ATTENTION MECHANISIM\n"
      ],
      "metadata": {
        "id": "kIhuEWQG-2a_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = sa_v2.W_query(inputs) #A\n",
        "keys = sa_v2.W_key(inputs)\n",
        "attn_scores = queries @ keys.T\n",
        "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAxY3FM9-5h2",
        "outputId": "68b3852c-b57d-413b-e164-b38c64cfd03e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
            "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
            "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
            "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
            "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = attn_scores.shape[0]\n",
        "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
        "print(mask_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gt-51Qq_BJV",
        "outputId": "7e046dd9-8a95-48c0-e288-a14f41c66708"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_simple = attn_weights*mask_simple\n",
        "print(masked_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGp4GERK_HVy",
        "outputId": "f906b3e1-6a79-4622-9abc-5c8aa1c19066"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
            "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_sums = masked_simple.sum(dim=1, keepdim=True)\n",
        "masked_simple_norm = masked_simple / row_sums\n",
        "print(masked_simple_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeJn_3Fr_MHP",
        "outputId": "0f47166f-89d4-47a5-a68a-26e72ed73720"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
            "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
        "print(masked)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz-kH2B6_RiB",
        "outputId": "f5025d89-c4c8-467a-87b4-1ac7cd0ae596"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
            "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
            "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
            "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
            "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
            "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuBz_UQN_eC0",
        "outputId": "facc4740-5160-4dd8-e457-5d7da291d45f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
            "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "dropout = torch.nn.Dropout(0.5) #A\n",
        "example = torch.ones(6, 6) #B\n",
        "print(dropout(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVdBZwb-_hOA",
        "outputId": "52e02027-1865-4ea2-fa1a-95de46fb5c49"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 2., 0., 2., 2., 0.],\n",
            "        [0., 0., 0., 2., 0., 2.],\n",
            "        [2., 2., 2., 2., 0., 2.],\n",
            "        [0., 2., 2., 0., 0., 2.],\n",
            "        [0., 2., 0., 2., 0., 2.],\n",
            "        [0., 2., 2., 2., 2., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "print(dropout(attn_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cLWR9Rf_vb0",
        "outputId": "fb5a1f67-855f-4e79-c09d-212bda6c91a4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],\n",
            "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "print(batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ogmf7rs_1Ae",
        "outputId": "d56b95da-7f7e-4485-a833-388d358adb3b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalAttention(nn.Module):\n",
        " def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "  super().__init__()\n",
        "  self.d_out = d_out\n",
        "  self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "  self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "  self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "  self.dropout = nn.Dropout(dropout) #A\n",
        "  self.register_buffer(\n",
        "   'mask',\n",
        "   torch.triu(torch.ones(context_length, context_length),\n",
        "   diagonal=1)) #B\n",
        " def forward(self, x):\n",
        "  b, num_tokens, d_in = x.shape #C\n",
        "  keys = self.W_key(x)\n",
        "  queries = self.W_query(x)\n",
        "  values = self.W_value(x)\n",
        "  attn_scores = queries @ keys.transpose(1, 2) #C\n",
        "  attn_scores.masked_fill_( #D\n",
        "  self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
        "  attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "  attn_weights = self.dropout(attn_weights)\n",
        "  context_vec = attn_weights @ values\n",
        "  return context_vec"
      ],
      "metadata": {
        "id": "CTVmC9Uh_-lk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "context_length = batch.shape[1]\n",
        "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
        "context_vecs = ca(batch)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yXa9AB-Ahqy",
        "outputId": "29f08973-1654-45ef-a0b8-1541a17e0b0b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context_vecs.shape: torch.Size([2, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MULTIHEAD ATTENTION CLASS"
      ],
      "metadata": {
        "id": "Jrh5SFPGCLXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionWrapper(nn.Module):\n",
        " def __init__(self, d_in, d_out, context_length,\n",
        " dropout, num_heads, qkv_bias=False):\n",
        "  super().__init__()\n",
        "  self.heads = nn.ModuleList(\n",
        "[CausalAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
        "for _ in range(num_heads)]\n",
        ")\n",
        " def forward(self, x):\n",
        "  return torch.cat([head(x) for head in self.heads], dim=-1)"
      ],
      "metadata": {
        "id": "qBHpOnd_Anb6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "context_length = batch.shape[1] # This is the number of tokens\n",
        "d_in, d_out = 3, 2\n",
        "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "context_vecs = mha(batch)\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhsEiz-yCczk",
        "outputId": "9f6afd04-3550-4615-8b11-7cb051c38803"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
            "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
            "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
            "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
            "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
            "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
            "\n",
            "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
            "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
            "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
            "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
            "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
            "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        " def __init__(self, d_in, d_out,\n",
        "context_length, dropout, num_heads, qkv_bias=False):\n",
        "  super().__init__()\n",
        "  assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "  self.d_out = d_out\n",
        "  self.num_heads = num_heads\n",
        "  self.head_dim = d_out // num_heads #A\n",
        "  self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "  self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "  self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "  self.out_proj = nn.Linear(d_out, d_out) #B\n",
        "  self.dropout = nn.Dropout(dropout)\n",
        "  self.register_buffer(\n",
        "'mask',\n",
        "torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        ")\n",
        " def forward(self, x):\n",
        "  b, num_tokens, d_in = x.shape\n",
        "  keys = self.W_key(x) #C\n",
        "  queries = self.W_query(x) #C\n",
        "  values = self.W_value(x) #C\n",
        "  keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) #D\n",
        "  values = values.view(b, num_tokens, self.num_heads, self.head_dim) #D\n",
        "  queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)#D\n",
        "  keys = keys.transpose(1, 2) #E\n",
        "  queries = queries.transpose(1, 2) #E\n",
        "  values = values.transpose(1, 2) #E\n",
        "  attn_scores = queries @ keys.transpose(2, 3) #F\n",
        "  mask_bool = self.mask.bool()[:num_tokens, :num_tokens] #G\n",
        "  attn_scores.masked_fill_(mask_bool, -torch.inf) #H\n",
        "  attn_weights = torch.softmax(\n",
        "  attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "  attn_weights = self.dropout(attn_weights)\n",
        "  context_vec = (attn_weights @ values).transpose(1, 2) #I\n",
        "#J\n",
        "  context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "  context_vec = self.out_proj(context_vec) #K\n",
        "  return context_vec"
      ],
      "metadata": {
        "id": "AcJ-6yY4CkBP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "\"vocab_size\": 50257, # Vocabulary size\n",
        "\"context_length\": 1024, # Context length\n",
        "\"emb_dim\": 768, # Embedding dimension\n",
        "\"n_heads\": 12, # Number of attention heads\n",
        "\"n_layers\": 12, # Number of layers\n",
        "\"drop_rate\": 0.1, # Dropout rate\n",
        "\"qkv_bias\": False # Query-Key-Value bias\n",
        "}"
      ],
      "metadata": {
        "id": "-jsCJhObD5-S"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAYER NORMALIZATION OF CODINNG GPT FROM SCRATCH\n"
      ],
      "metadata": {
        "id": "SS3u0yhh6RJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.manual_seed(123)\n",
        "batch_example=torch.randn(2,5)\n",
        "layers=nn.Sequential(nn.Linear(5,8),nn.ReLU())\n",
        "output=layers(batch_example)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0AY6h-W6Wh9",
        "outputId": "276f1afc-2aad-4795-87c3-0118e16b9620"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1377, 0.6193, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2500],\n",
            "        [0.1251, 0.5118, 0.0000, 0.0460, 0.2094, 0.1350, 0.0000, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean=torch.mean(output,dim=-1,keepdim=True)\n",
        "var=torch.var(output,dim=-1,keepdim=True)\n",
        "print(mean)\n",
        "print(var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-ZfXcAF7Y09",
        "outputId": "2db360d7-1298-45b7-e1cc-f002dd89be14"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1259],\n",
            "        [0.1284]], grad_fn=<MeanBackward1>)\n",
            "tensor([[0.0483],\n",
            "        [0.0300]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_norm=(output-mean)/torch.sqrt(var)\n",
        "print(output_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vOTr5iO7qRB",
        "outputId": "329f8eea-6336-4dc4-e439-50835534ecf3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0540,  2.2447, -0.5727, -0.5727, -0.5727, -0.5727, -0.5727,  0.5646],\n",
            "        [-0.0193,  2.2141, -0.7417, -0.4761,  0.4679,  0.0383, -0.7417, -0.7417]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean=output_norm.mean(dim=-1,keepdim=True,)\n",
        "var=output_norm.var(dim=-1,keepdim=True)\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "print(mean)\n",
        "print(var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDZQ0Bv08SuC",
        "outputId": "10e6c520-2e49-4a82-d241-ae9109a20664"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0.0000],\n",
            "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
            "tensor([[1.],\n",
            "        [1.]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer_norm(nn.Module):\n",
        "  def __init__(self,emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps=1e-5\n",
        "    self.scale=nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift=nn.Parameter(torch.zeros(emb_dim))\n",
        "  def forward(self,x):\n",
        "    mean=x.mean(dim=-1,keepdim=True)\n",
        "    var=x.var(dim=-1,keepdim=True,unbiased=False)\n",
        "    x_norm=(x-mean)/torch.sqrt(var+self.eps)\n",
        "    return self.scale*x_norm+self.shift\n",
        "\n"
      ],
      "metadata": {
        "id": "xuBDf0Bc8rkF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ln=Layer_norm(emb_dim=5)\n",
        "output_norm=ln.forward(batch_example)\n",
        "print(output_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02TLKINJ-tfx",
        "outputId": "87f15552-59a1-40ec-af0b-9a2f0fbca360"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5528,  1.0693, -0.0223,  0.2656, -1.8654],\n",
            "        [ 0.9087, -1.3767, -0.9564,  1.1304,  0.2940]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean=output_norm.mean(dim=-1,keepdim=True,)\n",
        "var=output_norm.var(dim=-1,keepdim=True)\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "print(mean)\n",
        "print(var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta0bQBbF_O7c",
        "outputId": "533d6d3b-f934-4ace-abd5-efa971bb5a30"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    -0.0000],\n",
            "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
            "tensor([[1.2499],\n",
            "        [1.2500]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTING FEED FORWARD WITH GELU ACTIVATION FUNCTION"
      ],
      "metadata": {
        "id": "hOKGRMjp_deT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NOTE:GELU FORMULAR= 0.5*X*(1+tanh[sqr(2/pi)*(x+0.044715*x^3)])\n",
        "class GELU(nn.Module):\n",
        "  def __init__(self,):\n",
        "    super().__init__()\n",
        "  def forward(self,x):\n",
        "    out=0.5*x*(1+torch.tanh(torch.sqrt(torch.tensor(2/torch.pi))*(x+0.044715*torch.pow(x,3))))\n",
        "    return out"
      ],
      "metadata": {
        "id": "3UKV8m_N_YFT"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "gelu,relu=GELU(),nn.ReLU()\n",
        "x=torch.linspace(-3,3,100)\n",
        "#torch.linspace creates  1D tensor like a list linspace means the number are evenly space between the starting and end(-3,3) and then 100 point between them\n",
        "out_gelu,out_relu=gelu(x),relu(x)\n",
        "fig,axes=plt.subplots(1,2,figsize=(10,5))\n",
        "axes[0].plot(x,out_gelu)\n",
        "axes[0].set_title(\"GELU\")\n",
        "axes[1].plot(x,out_relu)\n",
        "axes[1].set_title(\"RELU\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "TXJ-3zF0CQjw",
        "outputId": "071931f9-be2a-4315-d290-e969adb895ef"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.layers=nn.Sequential(nn.Linear(cfg[\"emb_dim\"],4*cfg[\"emb_dim\"]),GELU(),nn.Linear(4*cfg[\"emb_dim\"],cfg[\"emb_dim\"]))\n",
        "  def forward(self,X):\n",
        "    return self.layers(X)\n",
        ""
      ],
      "metadata": {
        "id": "HWJmxQtzGsac"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_class=FeedForward(GPT_CONFIG_124M)\n",
        "torch.manual_seed(123)\n",
        "x=torch.randn(2,3,768)\n",
        "print(word_class.forward(x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdPFduOWKOp1",
        "outputId": "aa2c5c00-3d69-44a7-8e31-1d852fabb4b2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WHole Transformer block"
      ],
      "metadata": {
        "id": "FXnz6vQkL3Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.attn=MultiHeadAttention(cfg[\"emb_dim\"],cfg[\"emb_dim\"],cfg[\"context_length\"],cfg[\"drop_rate\"],cfg[\"n_heads\"],cfg[\"qkv_bias\"])\n",
        "    self.ff=FeedForward(cfg)\n",
        "    self.ln1=Layer_norm(cfg[\"emb_dim\"])\n",
        "    self.ln2=Layer_norm(cfg[\"emb_dim\"])\n",
        "    self.dropout=nn.Dropout(cfg[\"drop_rate\"])\n",
        "  def forward(self,x):\n",
        "    shortcut=x\n",
        "    x=self.ln1(x)\n",
        "    x=self.attn(x)\n",
        "    x=self.dropout(x)\n",
        "    x=x+shortcut\n",
        "    shortcut=x\n",
        "    x=self.ln2(x)\n",
        "    x = self.ff(x)\n",
        "    x = self.dropout(x)\n",
        "    x = x + shortcut #C\n",
        "    return x"
      ],
      "metadata": {
        "id": "nXsw2uXWKOnv"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "x = torch.rand(2, 4, 768)\n",
        "block=TransformerBlock(GPT_CONFIG_124M)\n",
        "output = block(x)\n",
        "print(\"Input shape:\", x.shape)\n",
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPtfAwWlKH2Z",
        "outputId": "5dd31e94-1872-4d82-8604-05c94e4dbb12"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.token_embedding=nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
        "    self.pos_embedding=nn.Embedding(cfg[\"context_length\"],cfg[\"emb_dim\"])\n",
        "    self.drop_embd=nn.Dropout(cfg[\"drop_rate\"])\n",
        "    self.trf_blocks=nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "    self.final_ln=Layer_norm(cfg[\"emb_dim\"])\n",
        "    self.out_head=nn.Linear(cfg[\"emb_dim\"],cfg[\"vocab_size\"])\n",
        "  def forward(self, in_idx):\n",
        "   batch_size, seq_len = in_idx.shape\n",
        "   tok_embeds = self.token_embedding(in_idx)\n",
        "\n",
        "   pos_embeds = self.pos_embedding(torch.arange(seq_len, device=in_idx.device))\n",
        "   x = tok_embeds + pos_embeds\n",
        "   x = self.drop_embd(x)\n",
        "   x = self.trf_blocks(x)\n",
        "   x = self.final_ln(x)\n",
        "   logits = self.out_head(x)\n",
        "   return logits\n"
      ],
      "metadata": {
        "id": "79Lb8mITPH7M"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([\n",
        "    [1, 2, 3, 4],   # \"your journey starts now\"\n",
        "    [5, 6, 7, 1],   # \"one step with your\"\n",
        "    [2, 3, 5, 6]    # \"journey starts one step\"\n",
        "], dtype=torch.long)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model=GPTModel(GPT_CONFIG_124M)\n",
        "out=model(inputs)\n",
        "print(out.shape)\n",
        "print(inputs.shape)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SijOlAx1S7Lq",
        "outputId": "d8df5eb0-39e9-4a92-b2a0-78d119b0bfcf"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4, 50257])\n",
            "torch.Size([3, 4])\n",
            "tensor([[[ 0.3452, -0.3455, -0.4008,  ...,  0.0106,  0.3169, -0.6635],\n",
            "         [-0.0067, -0.0506, -0.1330,  ..., -1.0268, -0.4813, -0.6001],\n",
            "         [ 1.1256,  0.3055,  0.4729,  ...,  0.2663, -0.1870, -0.5688],\n",
            "         [-0.6487, -0.7881,  0.2156,  ...,  1.0692, -0.6893,  0.5354]],\n",
            "\n",
            "        [[-0.0656,  0.0789,  0.0397,  ...,  0.1924,  0.6326, -0.2203],\n",
            "         [ 0.3654,  0.0700,  0.7645,  ..., -0.6925,  0.4689, -0.0576],\n",
            "         [ 1.5007,  0.5435,  0.8134,  ...,  0.8527, -0.2737,  0.4322],\n",
            "         [ 0.3570,  0.1937, -0.1039,  ...,  1.0214,  0.2061, -0.0795]],\n",
            "\n",
            "        [[ 0.0624, -0.2568,  0.0322,  ..., -0.0175, -0.1768, -1.2995],\n",
            "         [ 0.1910, -0.4317,  0.2615,  ...,  0.4455,  0.2622, -0.1428],\n",
            "         [ 1.2842,  0.6724,  0.4588,  ...,  0.2005, -0.0030, -0.0221],\n",
            "         [ 0.0431, -0.3880,  0.1410,  ...,  0.7039, -0.3625,  0.1634]]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hiKZxLk2cdCB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}